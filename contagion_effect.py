# -*- coding: utf-8 -*-
"""paper_4_Contagion_for_github.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BMSAFcE0vUVI93lpxslAvVFh3zE65nYd

# **Importing packages**
"""



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx
from networkx.algorithms import tree
import matplotlib.cm as cm
# import community.community_louvain as lv
from sklearn.metrics.cluster import v_measure_score
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.api import VAR
from statsmodels.tools.eval_measures import rmse, aic
from PIL import Image
import io
import plotly.graph_objects as go
from google.colab import files

"""# **Reading datasets**"""

crypto_data = pd.read_csv("data/crypto_30min_filled_missing_value(ffill).csv")
stock_data = pd.read_csv("data/stock_30min_official_trading_filled_missing(ffill).csv")
index_data = pd.read_csv("data/etfs_filled.csv").drop(columns = ["Unnamed: 0"])
sp500_index = pd.read_csv("data/indices_30min_filled.csv")
# Remove some ETFs
remove_assets = ["GOVT","IEF", "IEI", "UVXY", "VIXM", "VIXY","VXX"]
index_data = index_data.drop(columns = remove_assets)

# Set the index column of each dataset to "date"
crypto_data = crypto_data.set_index("date")
stock_data = stock_data.set_index("date")
index_data = index_data.set_index("date")

# Get asset names
stock_names = list(stock_data.columns)
crypto_names = list(crypto_data.columns)
index_names = list(index_data.columns)
asset_names = stock_names + crypto_names + index_names


crypto_names_rm_UST = list(crypto_data.drop(columns = ["UST"]).columns)

# Merge all three datasets to one dataset
all_data = pd.concat([stock_data, crypto_data, index_data], axis =1, join = "inner")


"""**Convert to return values**"""

data = all_data.to_numpy() # Convert to numpy
names = all_data.columns
# Find log-returns
original = data[:-1]
onelag = data[1:]
logreturns = np.log(onelag) - np.log(original)

return_data = pd.DataFrame(data = logreturns, columns = asset_names)
return_data["date"] = all_data.reset_index()["date"][1:].values
return_data["date"] = pd.to_datetime(return_data["date"])
return_data = return_data.set_index(['date'])


return_data_rm_UST = return_data.drop(columns = ["UST"]) # UST has been dead since this time so we remove this cryptocurrency from the dataset during this period
names_rm_UST = return_data_rm_UST.columns

"""# **Minimum Spanning Tree and Community Detection**

**Correlation matrix of all assets over the entire period**
"""

return_numpy = return_data.to_numpy()
me = return_numpy.mean(axis = 0)
st = return_numpy.std(axis = 0)
st[st<0.0001] = 0.0001 # Make sure that the denominator is not zero

normalized = (return_numpy - me)/st

# find cross-correlation matrix
C = (1/len(return_numpy))*(normalized.T@normalized)


C[C>0.9999] = 1.0

# Plot the correlation matrix

fig, ax = plt.subplots(figsize=(32,32))
ax = sns.heatmap(C, cmap = 'OrRd', xticklabels= asset_names, yticklabels= asset_names, annot = False, ax = ax)
plt.xlabel("Assets")
plt.ylabel("Assets")
plt.title("Correlation between stocks, cryptocurrencies and US ETFs using Pearson")

"""The code below is to find the minimum spanning tree and then perform the community detection on this tree.

As explained in our paper, we split our data into 7 distinct periods, corresponding to a major event occurred in financial markets at that time and also the market condition. Thus, depends on which period you want to focus on, the corresponding specification in the code needs to modified. The list of periods are listed below, along with the corresponding specification in the code.

+ Pre-Covid-19 : 04/2019 - 12/2019 -> return_data[:2464]
+ Covid-19     : 01/2020 - 06/2020 -> return_data[2464:4089]
+ Bull Time 1: 07/2020 - 1/2021 -> return_data[4089:5988]
+ Bull Time 2: 02/2021 - 08/2021 -> return_data[5988:7912]
+ Bull Time 3: 09/2021 - 23/02/2022 -> return_data[7912:9479]
+ U-R Conflict 1: 24/02/2022 - 09/2022 -> return_data[9479:11455]
+ U-R Conflict 2: 10/2022 - 05/2023 -> return_data[11455:]

An example below is made using the last sub-period, i.e. U-R Conlfict 2. Hence, the return_data[11455:] is used.

We note that the Ukraine-Russia conflict period only has 221 assets since the UST asset has been removed during this period due to its crash. Consequently, to run the below code for this period, please use the data named "return_data_rm_UST"

**Constructing Minimum Spanning Tree**

**First - forming a correlation matrix, as described earlier**
"""

return_interval = return_data[11455:].to_numpy()
me = return_interval.mean(axis = 0)
st = return_interval.std(axis = 0)
st[st<0.0001] = 0.0001 # Make sure that the denominator is not zero

normalized = (return_interval - me)/st

# find cross-correlation matrix
C = (1/len(return_interval))*(normalized.T@normalized)


C[C>0.9999] = 1.0

"""**For UST Removal**"""

return_interval = return_data_rm_UST[11455:].to_numpy()
me = return_interval.mean(axis = 0)
st = return_interval.std(axis = 0)
st[st<0.0001] = 0.0001 # Make sure that the denominator is not zero

normalized = (return_interval - me)/st

# find cross-correlation matrix
C = (1/len(return_interval))*(normalized.T@normalized)


C[C>0.9999] = 1.0

"""**Second - Transforming the correlation matrix to Distance matrix**"""

D = np.sqrt(2*(1-C))
D[D<1e-7] = 0.0

"""**Third - Building a graph from the given distance matrix and extract the Minimum Spanning Tree from the graph**"""

# Forming a graph from the distance matrix - this is the fully connected graph
Graph_asset = nx.from_numpy_array(D, create_using= nx.Graph)
# Extracting the Minimum Spanning Tree from the graph
MST =  tree.minimum_spanning_edges(Graph_asset, algorithm= "kruskal", data = True)
mst_graph = nx.Graph()
mst_graph.add_nodes_from(names)
# Adding the name of assets to the Minimum Spanning Tree
for (node1, node2, _) in MST:
  mst_graph.add_edge(names[node1], names[node2])

"""**For UST Removal**"""

# Forming a graph from the distance matrix - this is the fully connected graph
Graph_asset = nx.from_numpy_array(D, create_using= nx.Graph)
# Extracting the Minimum Spanning Tree from the graph
MST =  tree.minimum_spanning_edges(Graph_asset, algorithm= "kruskal", data = True)
mst_graph = nx.Graph()
mst_graph.add_nodes_from(names_rm_UST)
# Adding the name of assets to the Minimum Spanning Tree
for (node1, node2, _) in MST:
  mst_graph.add_edge(names_rm_UST[node1], names_rm_UST[node2])

"""**Forth - Louvain Community Detection Algorithm**"""

louvain_partition = lv.best_partition(mst_graph)
louvain_df = pd.DataFrame.from_dict(louvain_partition,orient='index')
louvain_df.to_csv("drive/MyDrive/Plos_revision/louvain_community/louvain_(crypto_stock_etf)_tw7.csv")

"""**Plotting the graph and community detection results**"""

plt.figure(figsize = (20,20))
pos = nx.kamada_kawai_layout(mst_graph) # Set up the layout of the graph
cmap = cm.get_cmap('rainbow', max(louvain_partition.values()) + 1) # color the nodes according to their partition
widths = list(nx.get_edge_attributes(mst_graph,'width').values())
# Draw the graph and the Louvain community detection result
nx.draw(mst_graph, pos, node_size=340, cmap=cmap, node_color=list(louvain_partition.values()), with_labels = True, font_color= 'k', font_size = 14)
plt.savefig("drive/MyDrive/Plos_revision/community_detection/mst_tw7_withnoise(crypto_stock_etf).tiff", format = "tiff", dpi = 500)
plt.savefig("drive/MyDrive/Plos_revision/community_detection/mst_tw7_withnoise(crypto_stock_etf).png", dpi = 500)

"""# **Contagion Experiment**

+ Pre-Covid-19 : 04/2019 - 12/2019 -> return_data[:2464]
+ Covid-19     : 01/2020 - 06/2020 -> return_data[2464:4089]
+ Bull Time 1: 07/2020 - 1/2021 -> return_data[4089:5988]
+ Bull Time 2: 02/2021 - 08/2021 -> return_data[5988:7912]
+ Bull Time 3: 09/2021 - 23/02/2022 -> return_data[7912:9479]
+ U-R Conflict 1: 24/02/2022 - 09/2022 -> return_data[9479:11455]
+ U-R Conflict 2: 10/2022 - 05/2023 -> return_data[11455:]

**Testing Stationary for log-return time series**

Using Augmented Dickey-Fuller (ADF) for stationary test. The code below is an example using the Pre-Covid-19 sub-period (return[:2464])
"""

lc = []
cv = []
stationary_testing = {}
for asset in return_data.columns:
  result = adfuller(return_data[:2464][asset],autolag='AIC')
  level_of_confidence = [99 if result[1] < 0.01 else 95 if result[1] < 0.05 else 90 if result[1] < 0.1 else 0 ]
  lc.append(level_of_confidence)
  critical_value = [99 if result[0] <result[4]["1%"] else 95 if result[0] < result[4]["5%"] else 90 if result[0] < result[4]["10%"] else 0]
  cv.append(critical_value)
  if (level_of_confidence[0] > 80 and critical_value[0] > 80):
    stationary_testing[asset] = "stationary"
  else:
    stationary_testing[asset] = "non-stationary"

  if (stationary_testing[asset] == "non-stationary"):
    print("non-stationary: ",asset)

  print("finished: ", asset)

asset_df = pd.DataFrame(data = return_data.columns)
confidence_df = pd.DataFrame(data = lc)
critical_df = pd.DataFrame(data = cv)
stationary_df = pd.DataFrame(data = list(stationary_testing.values()))

stationary_df = pd.concat([asset_df, confidence_df,critical_df,stationary_df], axis = 1)
stationary_df.columns = ["Assets", "Confidence", "Critical Values", "Conclusion"]

stationary_df.to_csv("drive/MyDrive/Plos_revision/Contagion/stationary_test.csv")

"""**Choosing an appropriate order for VAR model**"""

var_model = VAR(return_data)

AIC = []
for i in [1,2,3,4,5,6,7,8,9,10]:
    scores = var_model.fit(i)
    print('Lag Order =', i)
    print('AIC : ', scores.aic)
    print('BIC : ', scores.bic)
    print('FPE : ', scores.fpe)
    print('HQIC: ', scores.hqic, '\n')
    AIC.append(scores.aic)

# Plotting AIC scores

plt.figure(figsize = (10,3))
plt.plot(np.arange(10), AIC)
plt.ylabel("AIC score",fontsize=14, fontweight='bold')
plt.xlabel("Order",fontsize=14, fontweight='bold')
plt.title("AIC scores for the Entire Period",fontsize=14, fontweight='bold')
plt.xticks(np.arange(10), np.arange(11)[1:])
plt.savefig("aic_entire.tiff", format = "tiff", dpi = 300, bbox_inches='tight',pad_inches = 0.1)
plt.savefig("aic_entire.png", dpi = 300,  bbox_inches='tight',pad_inches = 0.1)

"""# **VAR Model**

**Fitting the data into VAR model**

+ Pre-Covid-19 : 04/2019 - 12/2019 -> return_data[:2464]
+ Covid-19     : 01/2020 - 06/2020 -> return_data[2464:4089]
+ Bull Time 1: 07/2020 - 1/2021 -> return_data[4089:5988]
+ Bull Time 2: 02/2021 - 08/2021 -> return_data[5988:7912]
+ Bull Time 3: 09/2021 - 23/02/2022 -> return_data[7912:9479]
+ U-R Conflict 1: 24/02/2022 - 09/2022 -> return_data[9479:11455]
+ U-R Conflict 2: 10/2022 - 05/2023 -> return_data[11455:]

**Period 1**
"""

return_data[:2464]

var_model_ped1 = VAR(return_data[:2464])
result_var_1 = var_model_ped1.fit(2)
result_var_1.params[result_var_1.pvalues > 0.1 ] = 0.0
result_var_1.params.to_csv("contagion_ped1.csv")

"""**Period 2**"""

var_model_ped2 = VAR(return_data[2464:4089])
result_var_2 = var_model_ped2.fit(2)
result_var_2.params[result_var_2.pvalues > 0.1 ] = 0.0
result_var_2.params.to_csv("contagion_ped2.csv")

"""**Period 3**"""

var_model_ped3 = VAR(return_data[4089:5988])
result_var_3 = var_model_ped3.fit(2)
result_var_3.params[result_var_3.pvalues > 0.1 ] = 0.0
result_var_3.params.to_csv("contagion_ped3.csv")

"""**Period 4**"""

var_model_ped4 = VAR(return_data[5988:7912])
result_var_4 = var_model_ped4.fit(2)
result_var_4.params[result_var_4.pvalues > 0.1 ] = 0.0
result_var_4.params.to_csv("contagion_ped4.csv")

"""**Period 5**"""

var_model_ped5 = VAR(return_data[7912:9479])
result_var_5 = var_model_ped5.fit(2)
result_var_5.params[result_var_5.pvalues > 0.1 ] = 0.0
result_var_5.params.to_csv("contagion_ped5.csv")

"""**Period 6**"""

var_model_ped6 = VAR(return_data_rm_UST[9479:11455])
result_var_6 = var_model_ped6.fit(2)
result_var_6.params[result_var_6.pvalues > 0.1 ] = 0.0
result_var_6.params.to_csv("contagion_ped6.csv")

"""**Period 7**"""

var_model_ped7 = VAR(return_data_rm_UST[11455:])
result_var_7 = var_model_ped7.fit(2)
result_var_7.params[result_var_7.pvalues > 0.1 ] = 0.0
result_var_7.params.to_csv("contagion_ped7.csv")

"""# **Visualizing Figures**"""

def contagion_visualize_positive(data_contagion, zmax, tif_name):

  num_rows = data_contagion.shape[0]
  num_time_series = data_contagion.shape[1]

  # Create meshgrid for x and y axis
  x = np.arange(num_time_series)  # 146 points for time series indices
  y = np.arange(num_rows)         # 222 points for time steps

  # Create a mesh grid for plotting
  x_grid, y_grid = np.meshgrid(x, y)

  # Example data: replace this with your actual data

  z_grid = data_contagion.values  # Transpose to match the shape for surface plotting

  # Define a custom color scale with a solid color for zero
  custom_colorscale = [
      [0.0, "white"],      # Start with red for minimum values
      [1e-6, "green"],    # Middle is black for zero value
      [1.0, "green"]     # End with green for maximum values
  ]

  # Create the 3D plot with custom color scale
  fig = go.Figure()

  # Add the main surface plot for the data
  fig.add_trace(go.Surface(z=z_grid, x=x_grid, y=y_grid, colorscale=custom_colorscale,
                          name='Data Surface', showscale=False))

  # Add a white plate at z=0 to distinguish positive and negative values
  fig.add_trace(go.Surface(z=np.zeros_like(z_grid), x=x_grid, y=y_grid,
                          colorscale=[[0, 'white'], [1, 'white']],
                          showscale=False))

  # Add light gray plate for sticks 147-184
  light_gray_plate = np.zeros_like(z_grid)
  light_gray_plate[146:172, :] = 1e-3  # Set the rows for sticks 147-184

  # Add dark gray plate for sticks 185-222
  dark_gray_plate = np.zeros_like(z_grid)
  dark_gray_plate[172:, :] = 1e-3  # Set the rows for sticks 185-222

  # Add light gray plate at z=0 for sticks 147-184
  fig.add_trace(go.Surface(z=light_gray_plate, x=x_grid, y=y_grid,
                          colorscale=[[0, 'yellow'], [1, 'yellow']],
                          showscale=False, opacity=0.7))

  # Add dark gray plate at z=0 for sticks 185-222
  fig.add_trace(go.Surface(z=dark_gray_plate, x=x_grid, y=y_grid,
                          colorscale=[[0, 'orange'], [1, 'orange']],
                          showscale=False, opacity=0.7))


  # Update layout to enhance readability
  fig.update_layout(
      scene=dict(
          xaxis=dict(title= dict(text = 'Receivers', font=dict(size=32, weight='bold')), tickvals= [],
                    ticktext=[],
                    tickfont=dict(size=10),
                    backgroundcolor="rgb(255, 255, 255)", gridcolor="white",
                    showticklabels=False,showgrid=False,zeroline=False ),
          yaxis=dict(title= dict(text = 'Transmitters',font=dict(size=32, weight='bold')),  tickvals= [],
                    ticktext= [],
                    tickfont=dict(size=10),
                    backgroundcolor="rgb(255, 255, 255)", gridcolor="white",
                    showticklabels=False,showgrid=False,zeroline=False ),
          zaxis=dict(title= dict(text = 'Contagion Magnitude', font=dict(size=32, weight='bold')),tickfont=dict(size=18), backgroundcolor="rgb(255, 255, 255)", gridcolor="white",
                    showgrid=False,zeroline=False, range = [0.0, zmax]),
          camera=dict(
              eye=dict(x= -1.5, y= -0.2, z= 0.3),  # Adjust the camera position
                        # Define the 'up' direction
          ),
          aspectmode="manual",              # Fix aspect ratio manually
          aspectratio=dict(x=1, y=1, z=0.7)
      ),
      width = 2600,
      height = 2400,
      margin=dict(l=150, r=200, b=400, t=300)  # Adjust margins to reduce white space

  )

  img_bytes = fig.to_image(format="png",width=2600, height=2400)

  with Image.open(io.BytesIO(img_bytes)) as img:
      img.save(tif_name, format="TIFF")

  return fig

def contagion_visualize_negative(data_contagion, zmax, tif_name):
  num_rows = data_contagion.shape[0]
  num_time_series = data_contagion.shape[1]

  # Create meshgrid for x and y axis
  x = np.arange(num_time_series)  # 146 points for time series indices
  y = np.arange(num_rows)         # 222 points for time steps

  # Create a mesh grid for plotting
  x_grid, y_grid = np.meshgrid(x, y)

  # Example data: replace this with your actual data

  z_grid = np.abs(data_contagion.values)  # Transpose to match the shape for surface plotting

  # Define a custom color scale with a solid color for zero
  custom_colorscale = [
      [0.0, "white"],      # Start with red for minimum values
      [1e-6, "red"],    # Middle is black for zero value
      [1.0, "red"]     # End with green for maximum values
  ]

  # Create the 3D plot with custom color scale
  fig = go.Figure()

  # Add the main surface plot for the data
  fig.add_trace(go.Surface(z=z_grid, x=x_grid, y=y_grid, colorscale=custom_colorscale,
                          name='Data Surface', showscale=False))

  # Add a white plate at z=0 to distinguish positive and negative values
  fig.add_trace(go.Surface(z=np.zeros_like(z_grid), x=x_grid, y=y_grid,
                          colorscale=[[0, 'white'], [1, 'white']],
                          showscale=False))

  # Add light gray plate for sticks 147-184
  light_gray_plate = np.zeros_like(z_grid)
  light_gray_plate[146:172, :] = 1e-3  # Set the rows for sticks 147-184

  # Add dark gray plate for sticks 185-222
  dark_gray_plate = np.zeros_like(z_grid)
  dark_gray_plate[172:, :] = 1e-3  # Set the rows for sticks 185-222

  # Add light gray plate at z=0 for sticks 147-184
  fig.add_trace(go.Surface(z=light_gray_plate, x=x_grid, y=y_grid,
                          colorscale=[[0, 'yellow'], [1, 'yellow']],
                          showscale=False, opacity=0.7))

  # Add dark gray plate at z=0 for sticks 185-222
  fig.add_trace(go.Surface(z=dark_gray_plate, x=x_grid, y=y_grid,
                          colorscale=[[0, 'orange'], [1, 'orange']],
                          showscale=False, opacity=0.7))


  # Update layout to enhance readability
  fig.update_layout(
      scene=dict(
          xaxis=dict(title= dict(text = 'Receivers', font=dict(size=32, weight='bold')), tickvals= [],
                    ticktext=[],
                    tickfont=dict(size=10),
                    backgroundcolor="rgb(255, 255, 255)", gridcolor="white",
                    showticklabels=False,showgrid=False,zeroline=False ),
          yaxis=dict(title= dict(text = 'Transmitters',font=dict(size=32, weight='bold')),  tickvals= [],
                    ticktext= [],
                    tickfont=dict(size=10),
                    backgroundcolor="rgb(255, 255, 255)", gridcolor="white",
                    showticklabels=False,showgrid=False,zeroline=False ),
          zaxis=dict(title= dict(text = 'Contagion Magnitude', font=dict(size=32, weight='bold')),tickfont=dict(size=18), backgroundcolor="rgb(255, 255, 255)", gridcolor="white",
                    showgrid=False,zeroline=False, range = [0,zmax]),
          camera=dict(
              eye=dict(x= -1.5, y= -0.2, z= 0.3),  # Adjust the camera position
                        # Define the 'up' direction
          ),
          aspectmode="manual",              # Fix aspect ratio manually
          aspectratio=dict(x=1, y=1, z=0.7)
      ),
      width = 2600,
      height = 2400,
      margin=dict(l=150, r=200, b=400, t=300)  # Adjust margins to reduce white space

  )

  img_bytes = fig.to_image(format="png",width=2600, height=2400)

  with Image.open(io.BytesIO(img_bytes)) as img:
      img.save(tif_name, format="TIFF")



  return fig

def visualize_contagion_all(data_contagion, lag, zmax_negative, zmax_positive, list_of_stock, list_of_etf, list_of_crypto, folder_name, period_name, download = True):
  data_contagion["Lag"] = data_contagion["Unnamed: 0"].apply(lambda x: x[:2])
  data_contagion_lag = data_contagion[data_contagion["Lag"] == lag]
  print(data_contagion_lag)
  data_contagion_lag = data_contagion_lag.drop(columns = ["Unnamed: 0", "Lag"])


  # Separate negative and positive
  data_contagion_positive = data_contagion_lag.copy()
  data_contagion_positive[data_contagion_positive < 0.0] = 0.0

  data_contagion_negative = data_contagion_lag.copy()
  data_contagion_negative[data_contagion_negative > 0.0] = 0.0

  # Visualise all assets

  fig_positive_all_ped1 = contagion_visualize_positive(data_contagion_positive, zmax_positive, folder_name + "/all_asset_positive_" + lag + "_" + period_name + ".tiff")
  print("All assets positive done!")
  fig_negative_all_ped1 = contagion_visualize_negative(data_contagion_negative, zmax_negative, folder_name + "/all_asset_negative_" + lag + "_" + period_name + ".tiff")
  print("All assets negative done!")

  # Visualize each type of investment vehicle
  stock_contagion_positive = data_contagion_positive[list_of_stock]
  stock_contagion_negative = data_contagion_negative[list_of_stock]

  fig_positive_stock_ped1 = contagion_visualize_positive(stock_contagion_positive, zmax_positive, folder_name + "/stock_positive_" + lag + "_" + period_name + ".tiff")
  print("Stocks positive done!")
  fig_negative_stock_ped1 = contagion_visualize_negative(stock_contagion_negative, zmax_negative, folder_name + "/stock_negative_" + lag + "_" + period_name + ".tiff")
  print("Stocks negative done!")


  etf_contagion_positive = data_contagion_positive[list_of_etf]
  etf_contagion_negative = data_contagion_negative[list_of_etf]

  fig_positive_etf_ped1 = contagion_visualize_positive(etf_contagion_positive, zmax_positive, folder_name + "/etf_positive_" + lag + "_" + period_name + ".tiff")
  print("ETFs positive done!")
  fig_negative_etf_ped1 = contagion_visualize_negative(etf_contagion_negative, zmax_negative, folder_name + "/etf_negative_" + lag + "_" + period_name + ".tiff")
  print("ETFs negative done!")


  crypto_contagion_positive = data_contagion_positive[list_of_crypto]
  crypto_contagion_negative = data_contagion_negative[list_of_crypto]

  fig_positive_crypto_ped1 = contagion_visualize_positive(crypto_contagion_positive, zmax_positive, folder_name + "/crypto_positive_" + lag + "_" + period_name + ".tiff")
  print("Crypto positive done!")
  fig_negative_crypto_ped1 = contagion_visualize_negative(crypto_contagion_negative, zmax_negative, folder_name + "/crypto_negative_" + lag + "_" + period_name + ".tiff")
  print("Crypto negative done!")


  if (download == True):
    files.download(folder_name + "/all_asset_positive_" + lag + "_" + period_name + ".tiff")
    files.download(folder_name + "/all_asset_negative_" + lag + "_" + period_name + ".tiff")
    files.download(folder_name + "/stock_positive_" + lag + "_" + period_name + ".tiff")
    files.download(folder_name + "/stock_negative_" + lag + "_" + period_name + ".tiff")
    files.download(folder_name + "/etf_positive_" + lag + "_" + period_name + ".tiff")
    files.download(folder_name + "/etf_negative_" + lag + "_" + period_name + ".tiff")
    files.download(folder_name + "/crypto_positive_" + lag + "_" + period_name + ".tiff")
    files.download(folder_name + "/crypto_negative_" + lag + "_" + period_name + ".tiff")



  # # Generate Images
  # print("Generating images")

  # img_all_positive = fig_positive_all_ped1.to_image(format="png",width=2600, height=2400)
  # print("All assets positive done!")
  # img_all_negative = fig_negative_all_ped1.to_image(format="png",width=2600, height=2400)
  # print("All assets negative done!")
  # img_stock_positive = fig_positive_stock_ped1.to_image(format="png",width=2600, height=2400)
  # print("Stocks positive done!")
  # img_stock_negative = fig_negative_stock_ped1.to_image(format="png",width=2600, height=2400)
  # print("Stocks negative done!")
  # img_etf_positive = fig_positive_etf_ped1.to_image(format="png",width=2600, height=2400)
  # print("ETFs positive done!")
  # img_etf_negative = fig_negative_etf_ped1.to_image(format="png",width=2600, height=2400)
  # print("ETFs negative done!")
  # img_crypto_positive = fig_positive_crypto_ped1.to_image(format="png",width=2600, height=2400)
  # print("Crypto positive done!")
  # img_crypto_negative = fig_negative_crypto_ped1.to_image(format="png",width=2600, height=2400)
  # print("Crypto negative done!")

  # # Save TIFF images

  # print('Saving images')
  # with Image.open(io.BytesIO(img_all_positive)) as img:
  #     img.save("all_positive_ped1_" + lag +".tiff", format="TIFF")

  # with Image.open(io.BytesIO(img_all_negative)) as img:
  #     img.save("all_negative_ped1_" + lag +".tiff", format="TIFF")

  # with Image.open(io.BytesIO(img_stock_positive)) as img:
  #     img.save("stock_positive_ped1_" + lag +".tiff", format="TIFF")

  # with Image.open(io.BytesIO(img_stock_negative)) as img:
  #     img.save("stock_negative_ped1_" + lag +".tiff", format="TIFF")

  # with Image.open(io.BytesIO(img_etf_positive)) as img:
  #     img.save("etf_positive_ped1_" + lag +".tiff", format="TIFF")

  # with Image.open(io.BytesIO(img_etf_negative)) as img:
  #     img.save("etf_negative_ped1_" + lag +".tiff", format="TIFF")

  # with Image.open(io.BytesIO(img_crypto_positive)) as img:
  #     img.save("crypto_positive_ped1_" + lag +".tiff", format="TIFF")

  # with Image.open(io.BytesIO(img_crypto_negative)) as img:
  #     img.save("crypto_negative_ped1_" + lag +".tiff", format="TIFF")


  return fig_positive_all_ped1, fig_negative_all_ped1, fig_positive_stock_ped1, fig_negative_stock_ped1, fig_positive_etf_ped1, fig_negative_etf_ped1, fig_positive_crypto_ped1, fig_negative_crypto_ped1

"""**Visualizing the contagion effect during the last sub-period**"""

contagion_7 = pd.read_csv("contagion/contagion_ped7.csv")
_ = visualize_contagion_all(contagion_7, "L2", 24.0, 22.0, stock_names, index_names, crypto_names_rm_UST, "ped7_lag2", "ped7", download = True)

"""# **Assessment Metrics**"""

contagion_1 = pd.read_csv("contagion/contagion_ped1.csv")

contagion_1["Lag"] = contagion_1["Unnamed: 0"].apply(lambda x: x[:2])
contagion_data_lag = contagion_1[contagion_1["Lag"] == "L1"] # Consider Lag 1 only

def num_receiver_from_a_class(contagion_data, lag, list_of_receiver,list_of_transmiter):
  contagion_data["Lag"] = contagion_data["Unnamed: 0"].apply(lambda x: x[:2])
  contagion_data["Transmitter"] = contagion_data["Unnamed: 0"].apply(lambda x: x[3:])
  contagion_data_lag = contagion_data[contagion_data["Lag"] == lag]
  contagion_data_lag = contagion_data_lag.drop(columns = ["Unnamed: 0", "Lag"])
  contagion_data_lag = contagion_data_lag[contagion_data_lag["Transmitter"].isin(list_of_transmiter)]
  contagion_data_lag = contagion_data_lag.set_index("Transmitter")
  print(contagion_data_lag)

  contagion_data_abs = np.abs(contagion_data_lag)[list_of_receiver]


  return contagion_data_abs[contagion_data_abs > 0.0].count(axis = 1)

def average_transmitters(contagion_data, lag, list_of_stock, list_of_etf, list_of_crypto):
  contagion_dict = {"crypto_to_crypto": [], "stock_to_stock": [], "etf_to_etf": [],"stock_to_crypto": [], "etf_to_crypto": [], "crypto_to_stock": [], "etf_to_stock": [],
                    "crypto_to_etf": [], "stock_to_etf": []}
  contagion_data["Lag"] = contagion_data["Unnamed: 0"].apply(lambda x: x[:2])
  contagion_data_lag = contagion_data[contagion_data["Lag"] == lag]
  print(contagion_data_lag)
  contagion_data_lag = contagion_data_lag.drop(columns = ["Unnamed: 0", "Lag"])

  contagion_data_abs = np.abs(contagion_data_lag)
  # crypto -> crypto
  crypto_to_crypto =  contagion_data_abs[list_of_crypto][146:173]
  contagion_dict["crypto_to_crypto"] = crypto_to_crypto[crypto_to_crypto > 0.0].count().mean()
  # stock -> stock
  stock_to_stock = contagion_data_abs[list_of_stock][:146]
  contagion_dict["stock_to_stock"] = stock_to_stock[stock_to_stock > 0.0].count().mean()
  # etf -> etf
  etf_to_etf = contagion_data_abs[list_of_etf][173:]
  contagion_dict["etf_to_etf"] = etf_to_etf[etf_to_etf > 0.0].count().mean()
  # stock -> crypto
  stock_to_crypto = contagion_data_abs[list_of_crypto][:146]
  contagion_dict["stock_to_crypto"] = stock_to_crypto[stock_to_crypto> 0.0].count().mean()
  # etf -> crypto
  etf_to_crypto = contagion_data_abs[list_of_crypto][173:]
  contagion_dict["etf_to_crypto"] = etf_to_crypto[etf_to_crypto> 0.0].count().mean()
  # crypto -> stock
  crypto_to_stock = contagion_data_abs[list_of_stock][146:173]
  contagion_dict["crypto_to_stock"] = crypto_to_stock[crypto_to_stock > 0.0].count().mean()
  # etf -> stock
  etf_to_stock = contagion_data_abs[list_of_stock][173:]
  contagion_dict["etf_to_stock"] = etf_to_stock[etf_to_stock > 0.0].count().mean()
  # crypto -> etf
  crypto_to_etf = contagion_data_abs[list_of_etf][146:173]
  contagion_dict["crypto_to_etf"] = crypto_to_etf[crypto_to_etf > 0.0].count().mean()
  # stock -> etf
  stock_to_etf = contagion_data_abs[list_of_etf][:146]
  contagion_dict["stock_to_etf"] = stock_to_etf[stock_to_etf > 0.0].count().mean()

  return contagion_dict

def average_transmitters_rm_UST(contagion_data, lag, list_of_stock, list_of_etf, list_of_crypto):
  contagion_dict = {"crypto_to_crypto": [], "stock_to_stock": [], "etf_to_etf": [],"stock_to_crypto": [], "etf_to_crypto": [], "crypto_to_stock": [], "etf_to_stock": [],
                    "crypto_to_etf": [], "stock_to_etf": []}
  contagion_data["Lag"] = contagion_data["Unnamed: 0"].apply(lambda x: x[:2])
  contagion_data_lag = contagion_data[contagion_data["Lag"] == lag]
  print(contagion_data_lag)
  contagion_data_lag = contagion_data_lag.drop(columns = ["Unnamed: 0", "Lag"])

  contagion_data_abs = np.abs(contagion_data_lag)
  # crypto -> crypto
  crypto_to_crypto =  contagion_data_abs[list_of_crypto][146:172]
  contagion_dict["crypto_to_crypto"] = crypto_to_crypto[crypto_to_crypto > 0.0].count().mean()
  # stock -> stock
  stock_to_stock = contagion_data_abs[list_of_stock][:146]
  contagion_dict["stock_to_stock"] = stock_to_stock[stock_to_stock > 0.0].count().mean()
  # etf -> etf
  etf_to_etf = contagion_data_abs[list_of_etf][172:]
  contagion_dict["etf_to_etf"] = etf_to_etf[etf_to_etf > 0.0].count().mean()
  # stock -> crypto
  stock_to_crypto = contagion_data_abs[list_of_crypto][:146]
  contagion_dict["stock_to_crypto"] = stock_to_crypto[stock_to_crypto> 0.0].count().mean()
  # etf -> crypto
  etf_to_crypto = contagion_data_abs[list_of_crypto][172:]
  contagion_dict["etf_to_crypto"] = etf_to_crypto[etf_to_crypto> 0.0].count().mean()
  # crypto -> stock
  crypto_to_stock = contagion_data_abs[list_of_stock][146:172]
  contagion_dict["crypto_to_stock"] = crypto_to_stock[crypto_to_stock > 0.0].count().mean()
  # etf -> stock
  etf_to_stock = contagion_data_abs[list_of_stock][172:]
  contagion_dict["etf_to_stock"] = etf_to_stock[etf_to_stock > 0.0].count().mean()
  # crypto -> etf
  crypto_to_etf = contagion_data_abs[list_of_etf][146:172]
  contagion_dict["crypto_to_etf"] = crypto_to_etf[crypto_to_etf > 0.0].count().mean()
  # stock -> etf
  stock_to_etf = contagion_data_abs[list_of_etf][:146]
  contagion_dict["stock_to_etf"] = stock_to_etf[stock_to_etf > 0.0].count().mean()

  return contagion_dict

def average_contagion_magnitude(contagion_data, lag, list_of_stock, list_of_etf, list_of_crypto):
  contagion_dict = {"crypto_to_crypto": [], "stock_to_stock": [], "etf_to_etf": [],"stock_to_crypto": [], "etf_to_crypto": [], "crypto_to_stock": [], "etf_to_stock": [],
                    "crypto_to_etf": [], "stock_to_etf": []}
  contagion_data["Lag"] = contagion_data["Unnamed: 0"].apply(lambda x: x[:2])
  contagion_data_lag = contagion_data[contagion_data["Lag"] == lag]
  print(contagion_data_lag)
  contagion_data_lag = contagion_data_lag.drop(columns = ["Unnamed: 0", "Lag"])

  contagion_data_abs = np.abs(contagion_data_lag)

  # crypto -> crypto
  crypto_to_crypto =  contagion_data_abs[list_of_crypto][146:173]
  contagion_dict["crypto_to_crypto"] = crypto_to_crypto[crypto_to_crypto > 0.0].mean().mean()
  # stock -> stock
  stock_to_stock = contagion_data_abs[list_of_stock][:146]
  contagion_dict["stock_to_stock"] = stock_to_stock[stock_to_stock > 0.0].mean().mean()
  # etf -> etf
  etf_to_etf = contagion_data_abs[list_of_etf][173:]
  contagion_dict["etf_to_etf"] = etf_to_etf[etf_to_etf > 0.0].mean().mean()
  # stock -> crypto
  stock_to_crypto = contagion_data_abs[list_of_crypto][:146]
  contagion_dict["stock_to_crypto"] = stock_to_crypto[stock_to_crypto > 0.0].mean().mean()
  # etf -> crypto
  etf_to_crypto = contagion_data_abs[list_of_crypto][173:]
  contagion_dict["etf_to_crypto"] = etf_to_crypto[etf_to_crypto> 0.0].mean().mean()
  # crypto -> stock
  crypto_to_stock = contagion_data_abs[list_of_stock][146:173]
  contagion_dict["crypto_to_stock"] = crypto_to_stock[crypto_to_stock > 0.0].mean().mean()
  # etf -> stock
  etf_to_stock = contagion_data_abs[list_of_stock][173:]
  contagion_dict["etf_to_stock"] = etf_to_stock[etf_to_stock > 0.0].mean().mean()
  # crypto -> etf
  crypto_to_etf = contagion_data_abs[list_of_etf][146:173]
  contagion_dict["crypto_to_etf"] = crypto_to_etf[crypto_to_etf > 0.0].mean().mean()
  # stock -> etf
  stock_to_etf = contagion_data_abs[list_of_etf][:146]
  contagion_dict["stock_to_etf"] = stock_to_etf[stock_to_etf > 0.0].mean().mean()

  return contagion_dict

def average_contagion_magnitude_rm_UST(contagion_data, lag, list_of_stock, list_of_etf, list_of_crypto):
  contagion_dict = {"crypto_to_crypto": [], "stock_to_stock": [], "etf_to_etf": [],"stock_to_crypto": [], "etf_to_crypto": [], "crypto_to_stock": [], "etf_to_stock": [],
                    "crypto_to_etf": [], "stock_to_etf": []}
  contagion_data["Lag"] = contagion_data["Unnamed: 0"].apply(lambda x: x[:2])
  contagion_data_lag = contagion_data[contagion_data["Lag"] == lag]
  print(contagion_data_lag)
  contagion_data_lag = contagion_data_lag.drop(columns = ["Unnamed: 0", "Lag"])

  contagion_data_abs = np.abs(contagion_data_lag)

  # crypto -> crypto
  crypto_to_crypto =  contagion_data_abs[list_of_crypto][146:172]
  contagion_dict["crypto_to_crypto"] = crypto_to_crypto[crypto_to_crypto > 0.0].mean().mean()
  # stock -> stock
  stock_to_stock = contagion_data_abs[list_of_stock][:146]
  contagion_dict["stock_to_stock"] = stock_to_stock[stock_to_stock > 0.0].mean().mean()
  # etf -> etf
  etf_to_etf = contagion_data_abs[list_of_etf][172:]
  contagion_dict["etf_to_etf"] = etf_to_etf[etf_to_etf > 0.0].mean().mean()
  # stock -> crypto
  stock_to_crypto = contagion_data_abs[list_of_crypto][:146]
  contagion_dict["stock_to_crypto"] = stock_to_crypto[stock_to_crypto > 0.0].mean().mean()
  # etf -> crypto
  etf_to_crypto = contagion_data_abs[list_of_crypto][172:]
  contagion_dict["etf_to_crypto"] = etf_to_crypto[etf_to_crypto> 0.0].mean().mean()
  # crypto -> stock
  crypto_to_stock = contagion_data_abs[list_of_stock][146:172]
  contagion_dict["crypto_to_stock"] = crypto_to_stock[crypto_to_stock > 0.0].mean().mean()
  # etf -> stock
  etf_to_stock = contagion_data_abs[list_of_stock][172:]
  contagion_dict["etf_to_stock"] = etf_to_stock[etf_to_stock > 0.0].mean().mean()
  # crypto -> etf
  crypto_to_etf = contagion_data_abs[list_of_etf][146:172]
  contagion_dict["crypto_to_etf"] = crypto_to_etf[crypto_to_etf > 0.0].mean().mean()
  # stock -> etf
  stock_to_etf = contagion_data_abs[list_of_etf][:146]
  contagion_dict["stock_to_etf"] = stock_to_etf[stock_to_etf > 0.0].mean().mean()

  return contagion_dict

average_num_transmiters = average_transmitters(contagion_1, "L1", stock_names, index_names, crypto_names)

contagion_1 = pd.read_csv("contagion/contagion_ped1.csv")

average_magnitude = average_contagion_magnitude(contagion_1, "L1", stock_names, index_names, crypto_names)

average_magnitude

average_magnitude

average_num_transmiters_l2 = average_transmitters(contagion_1, "L2", stock_names, index_names, crypto_names)
average_magnitude_2 = average_contagion_magnitude(contagion_1, "L2", stock_names, index_names, crypto_names)

sub_period_list = ["Period 1", "Period 2", "Period 3", "Period 4","Period 5", "Period 6", "Period 7"]
num_transmitters_l1 = dict.fromkeys(["Period 1", "Period 2", "Period 3", "Period 4","Period 5", "Period 6", "Period 7"], [])
num_transmitters_l2 = dict.fromkeys(["Period 1", "Period 2", "Period 3", "Period 4","Period 5", "Period 6", "Period 7"], [])
contagion_magnitude_l1 = dict.fromkeys(["Period 1", "Period 2", "Period 3", "Period 4","Period 5", "Period 6", "Period 7"], [])
contagion_magnitude_l2 = dict.fromkeys(["Period 1", "Period 2", "Period 3", "Period 4","Period 5", "Period 6", "Period 7"], [])

contagion_1 = pd.read_csv("contagion/contagion_ped1.csv")
contagion_2 = pd.read_csv("contagion/contagion_ped2.csv")
contagion_3 = pd.read_csv("contagion/contagion_ped3.csv")
contagion_4 = pd.read_csv("contagion/contagion_ped4.csv")
contagion_5 = pd.read_csv("contagion/contagion_ped5.csv")
contagion_6 = pd.read_csv("contagion/contagion_ped6.csv")
contagion_7 = pd.read_csv("contagion/contagion_ped7.csv")

contagion_all = [contagion_1,contagion_2,contagion_3,contagion_4,contagion_5,contagion_6,contagion_7]

for i,key in zip(contagion_all[:-2],sub_period_list[:-2]):
  num_transmitters_l1[key] = average_transmitters(i, "L1", stock_names, index_names, crypto_names)
  num_transmitters_l2[key] = average_transmitters(i, "L2", stock_names, index_names, crypto_names)
  contagion_magnitude_l1[key] = average_contagion_magnitude(i, "L1", stock_names, index_names, crypto_names)
  contagion_magnitude_l2[key] = average_contagion_magnitude(i, "L2", stock_names, index_names, crypto_names)


for i,key in zip(contagion_all[-2:],sub_period_list[-2:]):
  num_transmitters_l1[key] = average_transmitters_rm_UST(i, "L1", stock_names, index_names, crypto_names_rm_UST)
  num_transmitters_l2[key] = average_transmitters_rm_UST(i, "L2", stock_names, index_names, crypto_names_rm_UST)
  contagion_magnitude_l1[key] = average_contagion_magnitude_rm_UST(i, "L1", stock_names, index_names, crypto_names_rm_UST)
  contagion_magnitude_l2[key] = average_contagion_magnitude_rm_UST(i, "L2", stock_names, index_names, crypto_names_rm_UST)

num_transmitters_l1_df = pd.DataFrame.from_dict(num_transmitters_l1)
num_transmitters_l2_df = pd.DataFrame.from_dict(num_transmitters_l2)
contagion_magnitude_l1_df = pd.DataFrame.from_dict(contagion_magnitude_l1)
contagion_magnitude_l2_df = pd.DataFrame.from_dict(contagion_magnitude_l2)

num_transmitters_l1_df.to_csv("num_transmitters_overtime_l1.csv")
num_transmitters_l2_df.to_csv("num_transmitters_overtime_l2.csv")
contagion_magnitude_l1_df.to_csv("contagion_magnitude_l1.csv")
contagion_magnitude_l2_df.to_csv("contagion_magnitude_l2.csv")

"""**Top transmitters**"""

contagion_1 = pd.read_csv("contagion/contagion_ped1.csv")
contagion_2 = pd.read_csv("contagion/contagion_ped2.csv")
contagion_3 = pd.read_csv("contagion/contagion_ped3.csv")
contagion_4 = pd.read_csv("contagion/contagion_ped4.csv")
contagion_5 = pd.read_csv("contagion/contagion_ped5.csv")
contagion_6 = pd.read_csv("contagion/contagion_ped6.csv")
contagion_7 = pd.read_csv("contagion/contagion_ped7.csv")

num_receiver_from_a_class()

sub_period_list = ["Period 1", "Period 2", "Period 3", "Period 4","Period 5", "Period 6", "Period 7"]
num_receivers_l1 = dict.fromkeys(["Period 1", "Period 2", "Period 3", "Period 4","Period 5", "Period 6", "Period 7"], [])

contagion_1 = pd.read_csv("contagion/contagion_ped1.csv")
contagion_2 = pd.read_csv("contagion/contagion_ped2.csv")
contagion_3 = pd.read_csv("contagion/contagion_ped3.csv")
contagion_4 = pd.read_csv("contagion/contagion_ped4.csv")
contagion_5 = pd.read_csv("contagion/contagion_ped5.csv")
contagion_6 = pd.read_csv("contagion/contagion_ped6.csv")
contagion_7 = pd.read_csv("contagion/contagion_ped7.csv")

contagion_all = [contagion_1,contagion_2,contagion_3,contagion_4,contagion_5,contagion_6,contagion_7]

for i,key in zip(contagion_all[:-2],sub_period_list[:-2]):
  num_receivers_l1[key] = list(num_receiver_from_a_class(i, "L1", crypto_names, index_names).sort_values(ascending = False).head(3).index)


for i,key in zip(contagion_all[-2:],sub_period_list[-2:]):
  num_receivers_l1[key] = list(num_receiver_from_a_class(i, "L1", crypto_names_rm_UST, index_names).sort_values(ascending = False).head(3).index)

num_receivers = pd.DataFrame.from_dict(num_receivers_l1)

# for i in num_receivers:
#   print(num_receivers[i].max())



